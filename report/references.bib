
% Journals

% First the Full Name is given, then the abbreviation used in the AMS Math
% Reviews, with an indication if it could not be found there.
% Note the 2nd overwrites the 1st, so swap them if you want the full name.

 %{AMS}
 @string{AMSTrans = "American Mathematical Society Translations"}
 @string{AMSTrans = "Amer. Math. Soc. Transl."}
 @string{BullAMS = "Bulletin of the American Mathematical Society"}
 @string{BullAMS = "Bull. Amer. Math. Soc."}
 @string{ProcAMS = "Proceedings of the American Mathematical Society"}
 @string{ProcAMS = "Proc. Amer. Math. Soc."}
 @string{TransAMS = "Transactions of the American Mathematical Society"}
 @string{TransAMS = "Trans. Amer. Math. Soc."}

 %ACM
 @string{CACM = "Communications of the {ACM}"}
 @string{CACM = "Commun. {ACM}"}
 @string{CompServ = "Comput. Surveys"}
 @string{JACM = "J. ACM"}
 @string{ACMMathSoft = "{ACM} Transactions on Mathematical Software"}
 @string{ACMMathSoft = "{ACM} Trans. Math. Software"}
 @string{SIGNUM = "{ACM} {SIGNUM} Newsletter"}
 @string{SIGNUM = "{ACM} {SIGNUM} Newslett."}

 @string{AmerSocio = "American Journal of Sociology"}
 @string{AmerStatAssoc = "Journal of the American Statistical Association"}
 @string{AmerStatAssoc = "J. Amer. Statist. Assoc."}
 @string{ApplMathComp = "Applied Mathematics and Computation"}
 @string{ApplMathComp = "Appl. Math. Comput."}
 @string{AmerMathMonthly = "American Mathematical Monthly"}
 @string{AmerMathMonthly = "Amer. Math. Monthly"}
 @string{BIT = "{BIT}"}
 @string{BritStatPsych = "British Journal of Mathematical and Statistical
                           Psychology"}
 @string{BritStatPsych = "Brit. J. Math. Statist. Psych."}
 @string{CanMathBull = "Canadian Mathematical Bulletin"}
 @string{CanMathBull = "Canad. Math. Bull."}
 @string{CompApplMath = "Journal of Computational and Applied Mathematics"}
 @string{CompApplMath = "J. Comput. Appl. Math."}
 @string{CompPhys = "Journal of Computational Physics"}
 @string{CompPhys = "J. Comput. Phys."}
 @string{CompStruct = "Computers and Structures"}
 @string{CompStruct = "Comput. \& Structures"}
 @string{CompJour = "The Computer Journal"}
 @string{CompJour = "Comput. J."}
 @string{CompSysSci = "Journal of Computer and System Sciences"}
 @string{CompSysSci = "J. Comput. System Sci."}
 @string{Computing = "Computing"}
 @string{ContempMath = "Contemporary Mathematics"}
 @string{ContempMath = "Contemp. Math."}
 @string{Crelle = "Crelle's Journal"}
 @string{GiornaleMath = "Giornale di Mathematiche"}
 @string{GiornaleMath = "Giorn. Mat."} % didn't find in AMS MR., ibid.

 %IEEE
 @string{Computer = "{IEEE} Computer"}
 @string{IEEETransComp = "{IEEE} Transactions on Computers"}
 @string{IEEETransComp = "{IEEE} Trans. Comput."}
 @string{IEEETransAC = "{IEEE} Transactions on Automatic Control"}
 @string{IEEETransAC = "{IEEE} Trans. Automat. Control"}
 @string{IEEESpec = "{IEEE} Spectrum"} % didn't find in AMS MR
 @string{ProcIEEE = "Proceedings of the {IEEE}"}
 @string{ProcIEEE = "Proc. {IEEE}"} % didn't find in AMS MR
 @string{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic
                               Systems"}
 @string{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems"}

 @string{IMANumerAna = "{IMA} Journal of Numerical Analysis"}
 @string{IMANumerAna = "{IMA} J. Numer. Anal."}
 @string{InfProcLet = "Information Processing Letters"}
 @string{InfProcLet = "Inform. Process. Lett."}
 @string{InstMathApp = "Journal of the Institute of Mathematics and its
                         Applications"}
 @string{InstMathApp = "J. Inst. Math. Appl."}
 @string{IntControl = "International Journal of Control"}
 @string{IntControl = "Internat. J. Control"}
 @string{IntNumerEng = "International Journal for Numerical Methods in
                         Engineering"}
 @string{IntNumerEng = "Internat. J. Numer. Methods Engrg."}
 @string{IntSuper = "International Journal of Supercomputing Applications"}
 @string{IntSuper = "Internat. J. Supercomputing Applic."} % didn't find
%% in AMS MR
 @string{Kibernetika = "Kibernetika"}
 @string{JResNatBurStand = "Journal of Research of the National Bureau of
                             Standards"}
 @string{JResNatBurStand = "J. Res. Nat. Bur. Standards"}
 @string{LinAlgApp = "Linear Algebra and its Applications"}
 @string{LinAlgApp = "Linear Algebra Appl."}
 @string{MathAnaAppl = "Journal of Mathematical Analysis and Applications"}
 @string{MathAnaAppl = "J. Math. Anal. Appl."}
 @string{MathAnnalen = "Mathematische Annalen"}
 @string{MathAnnalen = "Math. Ann."}
 @string{MathPhys = "Journal of Mathematical Physics"}
 @string{MathPhys = "J. Math. Phys."}
 @string{MathComp = "Mathematics of Computation"}
 @string{MathComp = "Math. Comp."}
 @string{MathScand = "Mathematica Scandinavica"}
 @string{MathScand = "Math. Scand."}
 @string{TablesAidsComp = "Mathematical Tables and Other Aids to Computation"}
 @string{TablesAidsComp = "Math. Tables Aids Comput."}
 @string{NumerMath = "Numerische Mathematik"}
 @string{NumerMath = "Numer. Math."}
 @string{PacificMath = "Pacific Journal of Mathematics"}
 @string{PacificMath = "Pacific J. Math."}
 @string{ParDistComp = "Journal of Parallel and Distributed Computing"}
 @string{ParDistComp = "J. Parallel and Distrib. Comput."} % didn't find
%% in AMS MR
 @string{ParComputing = "Parallel Computing"}
 @string{ParComputing = "Parallel Comput."}
 @string{PhilMag = "Philosophical Magazine"}
 @string{PhilMag = "Philos. Mag."}
 @string{ProcNAS = "Proceedings of the National Academy of Sciences of the USA"}
 @string{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A."}
 @string{Psychometrika = "Psychometrika"}
 @string{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)"}
 @string{QuartMath = "Quart. J. Math. Oxford Ser. (2)"}
 @string{QuartApplMath = "Quarterly of Applied Mathematics"}
 @string{QuartApplMath = "Quart. Appl. Math."}
 @string{RevueInstStat = "Review of the International Statisical Institute"}
 @string{RevueInstStat = "Rev. Inst. Internat. Statist."}

 %SIAM
 @string{JSIAM = "Journal of the Society for Industrial and Applied Mathematics
                   "}
 @string{JSIAM = "J. Soc. Indust. Appl. Math."}
 @string{JSIAMB = "Journal of the Society for Industrial and Applied
                    Mathematics, Series B, Numerical Analysis"}
 @string{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal."}
 @string{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods"}
 @string{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods"}
 @string{SIAMAppMath = "{SIAM} Journal on Applied Mathematics"}
 @string{SIAMAppMath = "{SIAM} J. Appl. Math."}
 @string{SIAMComp = "{SIAM} Journal on Computing"}
 @string{SIAMComp = "{SIAM} J. Comput."}
 @string{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications"}
 @string{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl."}
 @string{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis"}
 @string{SIAMNumAnal = "{SIAM} J. Numer. Anal."}
 @string{SIAMReview = "{SIAM} Review"}
 @string{SIAMReview = "{SIAM} Rev."}
 @string{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical Computing"}
 @string{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput."}

 @string{SoftPracExp = "Software Practice and Experience"}
 @string{SoftPracExp = "Software Prac. Experience"} % didn't find in AMS MR
 @string{StatScience = "Statistical Science"}
 @string{StatScience = "Statist. Sci."}
 @string{Techno = "Technometrics"}
 @string{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical
                              Physics"}
 @string{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys."}
 @string{VLSICompSys = "Journal of {VLSI} and Computer Systems"}
 @string{VLSICompSys = "J. {VLSI} Comput. Syst."}
 @string{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und Mechanik"}
 @string{ZAngewMathMech = "Z. Angew. Math. Mech."}
 @string{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik"}
 @string{ZAngewMathPhys = "Z. Angew. Math. Phys."}

% Publishers % ================================================= |

 @string{Academic = "Academic Press"}
 @string{ACMPress = "{ACM} Press"}
 @string{AdamHilger = "Adam Hilger"}
 @string{AddisonWesley = "Addison-Wesley"}
 @string{AllynBacon = "Allyn and Bacon"}
 @string{AMS = "American Mathematical Society"}
 @string{Birkhauser = "Birkha{\"u}ser"}
 @string{CambridgePress = "Cambridge University Press"}
 @string{Chelsea = "Chelsea"}
 @string{ClaredonPress = "Claredon Press"}
 @string{DoverPub = "Dover Publications"}
 @string{Eyolles = "Eyolles"}
 @string{HoltRinehartWinston = "Holt, Rinehart and Winston"}
 @string{Interscience = "Interscience"}
 @string{JohnsHopkinsPress = "The Johns Hopkins University Press"}
 @string{JohnWileySons = "John Wiley and Sons"}
 @string{Macmillan = "Macmillan"}
 @string{MathWorks = "The Math Works Inc."}
 @string{McGrawHill = "McGraw-Hill"}
 @string{NatBurStd = "National Bureau of Standards"}
 @string{NorthHolland = "North-Holland"}
 @string{OxfordPress = "Oxford University Press"}  %address Oxford or London?
 @string{PergamonPress = "Pergamon Press"}
 @string{PlenumPress = "Plenum Press"}
 @string{PrenticeHall = "Prentice-Hall"}
 @string{SIAMPub = "{SIAM} Publications"}
 @string{Springer = "Springer-Verlag"}
 @string{TexasPress = "University of Texas Press"}
 @string{VanNostrand = "Van Nostrand"}
 @string{WHFreeman = "W. H. Freeman and Co."}

%Entries

@inproceedings{gar,
 author = {MacAvaney, Sean and Tonellotto, Nicola and Macdonald, Craig},
 title = {Adaptive Re-Ranking with a Corpus Graph},
 year = {2022},
 isbn = {9781450392365},
 publisher = {Association for Computing Machinery},
 address = {New York, NY, USA},
 url = {https://doi.org/10.1145/3511808.3557231},
 doi = {10.1145/3511808.3557231},
 abstract = {Search systems often employ a re-ranking pipeline, wherein
             documents (or passages) from an initial pool of candidates are
             assigned new ranking scores. The process enables the use of
             highly-effective but expensive scoring functions that are not
             suitable for use directly in structures like inverted indices or
             approximate nearest neighbour indices. However, re-ranking pipelines
             are inherently limited by the recall of the initial candidate pool;
             documents that are not identified as candidates for re-ranking by
             the initial retrieval function cannot be identified. We propose a
             novel approach for overcoming the recall limitation based on the
             well-established clustering hypothesis. Throughout the re-ranking
             process, our approach adds documents to the pool that are most
             similar to the highest-scoring documents up to that point. This
             feedback process adapts the pool of candidates to those that may
             also yield high ranking scores, even if they were not present in the
             initial pool. It can also increase the score of documents that
             appear deeper in the pool that would have otherwise been skipped due
             to a limited re-ranking budget. We find that our Graph-based
             Adaptive Re-ranking (GAR) approach significantly improves the
             performance of re-ranking pipelines in terms of precision- and
             recall-oriented measures, is complementary to a variety of existing
             techniques (e.g., dense retrieval), is robust to its hyperparameters
             , and contributes minimally to computational and storage costs. For
             instance, on the MS MARCO passage ranking dataset, GAR can improve
             the nDCG of a BM25 candidate pool by up to 8\% when applying a
             monoT5 ranker.},
 booktitle = {Proceedings of the 31st ACM International Conference on
              Information \& Knowledge Management},
 pages = {1491--1500},
 numpages = {10},
 keywords = {neural re-ranking, clustering hypothesis},
 location = {Atlanta, GA, USA},
 series = {CIKM '22},
}
@inproceedings{ladr,
 author = {Kulkarni, Hrishikesh and MacAvaney, Sean and Goharian, Nazli and
           Frieder, Ophir},
 title = {Lexically-Accelerated Dense Retrieval},
 year = {2023},
 isbn = {9781450394086},
 publisher = {Association for Computing Machinery},
 address = {New York, NY, USA},
 url = {https://doi.org/10.1145/3539618.3591715},
 doi = {10.1145/3539618.3591715},
 abstract = {Retrieval approaches that score documents based on learned dense
             vectors (i.e., dense retrieval) rather than lexical signals (i.e. ,
             conventional retrieval) are increasingly popular. Their ability to
             identify related documents that do not necessarily contain the same
             terms as those appearing in the user's query (thereby improving
             recall) is one of their key advantages. However, to actually achieve
             these gains, dense retrieval approaches typically require an
             exhaustive search over the document collection, making them
             considerably more expensive at query-time than conventional lexical
             approaches. Several techniques aim to reduce this computational
             overhead by approximating the results of a full dense retriever.
             Although these approaches reasonably approximate the top results,
             they suffer in terms of recall -- one of the key advantages of dense
             retrieval. We introduce 'LADR' (Lexically-Accelerated Dense
             Retrieval), a simple-yet-effective approach that improves the
             efficiency of existing dense retrieval models without compromising
             on retrieval effectiveness. LADR uses lexical retrieval techniques
             to seed a dense retrieval exploration that uses a document proximity
             graph. Through extensive experiments, we find that LADR establishes
             a new dense retrieval effectiveness-efficiency Pareto frontier among
             approximate k nearest neighbor techniques. When tuned to take around
             8ms per query in retrieval latency on our hardware, LADR
             consistently achieves both precision and recall that are on par with
             an exhaustive search on standard benchmarks. Importantly, LADR
             accomplishes this using only a single CPU -- no hardware
             accelerators such as GPUs -- which reduces the deployment cost of
             dense retrieval systems.},
 booktitle = {Proceedings of the 46th International ACM SIGIR Conference on
              Research and Development in Information Retrieval},
 pages = {152–162},
 numpages = {11},
 keywords = {adaptive re-ranking, approximate k nearest neighbor, dense
             retrieval},
 location = {, Taipei, Taiwan, },
 series = {SIGIR '23},
}

@inproceedings{query-document,
 author = {Frayling, Erlend MacAvaney, Sean Macdonald, Craig Ounis, Iadh},
 editor = {Goharian, Nazli Tonellotto, Nicola He, Yulan Lipani, Aldo McDonald ,
           Graham Macdonald, Craig Ounis, Iadh},
 title = {Effective Adhoc Retrieval Through Traversal of a Query-Document Graph},
 booktitle = {Advances in Information Retrieval},
 abstract = {Adhoc retrieval is the task of effectively retrieving information
             for an end-user's information need, usually expressed as a textual
             query. One of the most well-established retrieval frameworks is the
             two-stage retrieval pipeline, whereby an inexpensive retrieval
             algorithm retrieves a subset of candidate documents from a corpus,
             and a more sophisticated (but costly) model re-ranks these
             candidates. A notable limitation of this two-stage framework is that
             the second stage re-ranking model can only re-order documents, and
             any relevant documents not retrieved from the corpus in the first
             stage are entirely lost to the second stage. A recently-proposed
             Adaptive Re-Ranking technique has shown that extending the candidate
             pool by traversing a document similarity graph can overcome this
             recall problem. However, this traversal technique is agnostic of the
             user's query , which has the potential to waste compute resources by
             scoring documents that are not related to the query. In this work,
             we propose an alternative formulation of the document similarity
             graph. Rather than using document similarities, we propose a
             weighted bipartite graph that consists of both document nodes and
             query nodes. This overcomes the limitations of prior Adaptive
             Re-Ranking approaches because the bipartite graph can be navigated
             in a manner that explicitly acknowledges the original user query
             issued to the search pipeline. We evaluate the effectiveness of our
             proposed framework by experimenting with the TREC Deep Learning
             track in a standard adhoc retrieval setting. We find that our
             approach outperforms state-of-the-art two-stage re-ranking pipelines
             , improving the nDCG@10 metric by 5.8{\%} on the DL19 test
             collection.},
 year = {2024},
 publisher = {Springer Nature Switzerland},
 address = {Cham},
 pages = {89--104},
 isbn = {978-3-031-56063-7},
}

@article{clustering_hypothesis,
 title = {The use of hierarchic clustering in information retrieval},
 journal = {Information Storage and Retrieval},
 volume = {7},
 number = {5},
 pages = {217-240},
 year = {1971},
 issn = {0020-0271},
 doi = {https://doi.org/10.1016/0020-0271(71)90051-9},
 url = {https://www.sciencedirect.com/science/article/pii/0020027171900519},
 author = {N. Jardine and C.J. {van Rijsbergen}},
 abstract = {We introduce information retrieval strategies which are based on
             automatic hierarchic clustering of documents. We discuss the
             evaluation of retrieval strategies and show, using a subset of the
             Cranfield Aeronautics document collection, that cluster-based
             retrieval strategies can be devised which are as effective as linear
             associative retrieval strategies and much more efficient. Finally,
             we outline how cluster-based retrieval may be extended to large
             growing document collections and indicate some ways in which the
             effectiveness of cluster-based retrieval strategies may be improved.
             },
}

@inproceedings{spade,
 author = {Choi, Eunseong and Lee, Sunkyung and Choi, Minjin and Ko, Hyeseon and
           Song, Young-In and Lee, Jongwuk},
 title = {SpaDE: Improving Sparse Representations using a Dual Document Encoder
          for First-stage Retrieval},
 year = {2022},
 isbn = {9781450392365},
 publisher = {Association for Computing Machinery},
 address = {New York, NY, USA},
 url = {https://doi.org/10.1145/3511808.3557456},
 doi = {10.1145/3511808.3557456},
 abstract = {Sparse document representations have been widely used to retrieve
             relevant documents via exact lexical matching. Owing to the
             pre-computed inverted index, it supports fast ad-hoc search but
             incurs the vocabulary mismatch problem. Although recent neural
             ranking models using pre-trained language models can address this
             problem, they usually require expensive query inference costs,
             implying the trade-off between effectiveness and efficiency.
             Tackling the trade-off, we propose a novel uni-encoder ranking model
             , Sparse retriever using a Dual document Encoder (SpaDE), learning
             document representation via the dual encoder. Each encoder plays a
             central role in (i) adjusting the importance of terms to improve
             lexical matching and (ii) expanding additional terms to support
             semantic matching. Furthermore, our co-training strategy trains the
             dual encoder effectively and avoids unnecessary intervention in
             training each other. Experimental results on several benchmarks show
             that SpaDE outperforms existing uni-encoder ranking models.},
 booktitle = {Proceedings of the 31st ACM International Conference on
              Information \& Knowledge Management},
 pages = {272–282},
 numpages = {11},
 keywords = {neural ranking, pre-trained language model, sparse representations},
 location = {Atlanta, GA, USA},
 series = {CIKM '22},
}

@article{hnsw,
 author = {Malkov, Yu A. and Yashunin, D. A.},
 journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
 title = {Efficient and Robust Approximate Nearest Neighbor Search Using
          Hierarchical Navigable Small World Graphs},
 year = {2020},
 volume = {42},
 number = {4},
 pages = {824-836},
 keywords = {Routing;Complexity theory;Search problems;Data models;Approximation
             algorithms;Biological system modeling;Brain modeling;Graph and tree
             search strategies;artificial intelligence;information search and
             retrieval;information storage and retrieval;information technology
             and systems;search process;graphs and networks;data
             structures;nearest neighbor search;big data;approximate
             search;similarity search},
 doi = {10.1109/TPAMI.2018.2889473},
}

@inproceedings{doc2query,
 author = {Gospodinov, Mitko and MacAvaney, Sean and Macdonald, Craig},
 editor = {Kamps, Jaap and Goeuriot, Lorraine and Crestani, Fabio and Maistro,
           Maria and Joho, Hideo and Davis, Brian and Gurrin, Cathal and
           Kruschwitz, Udo and Caputo, Annalina},
 title = {Doc2Query--: When Less is More},
 booktitle = {Advances in Information Retrieval},
 year = {2023},
 publisher = {Springer Nature Switzerland},
 address = {Cham},
 pages = {414--422},
 abstract = {Doc2Query---the process of expanding the content of a document
             before indexing using a sequence-to-sequence model---has emerged as
             a prominent technique for improving the first-stage retrieval
             effectiveness of search engines. However, sequence-to-sequence
             models are known to be prone to ``hallucinating'' content that is
             not present in the source text. We argue that Doc2Query is indeed
             prone to hallucination, which ultimately harms retrieval
             effectiveness and inflates the index size. In this work, we explore
             techniques for filtering out these harmful queries prior to
             indexing. We find that using a relevance model to remove
             poor-quality queries can improve the retrieval effectiveness of
             Doc2Query by up to 16{\%}, while simultaneously reducing mean query
             execution time by 30{\%} and cutting the index size by 48{\%}. We
             release the code, data, and a live demonstration to facilitate
             reproduction and further exploration
             (https://github.com/terrierteam/pyterrier{\_}doc2query).},
 isbn = {978-3-031-28238-6},
}
