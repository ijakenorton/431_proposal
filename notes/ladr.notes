
ladr "ladr uses lexical retrieval to seed a dense retrieval exploration that uses a document
proximity graph"

ladr estabilishes a new effectiveness-effeciency pareto frontier, while only requiring a cpu, this
gives it a considerable advantage interms of cost and easy of deployment.

instead of working on a completely new paradigm, ladr aims to build off of more traditional
lexigraphical techniques, namely, an initial ranking using bm25 to create top k document pool
efficiently followed by later re-ranking with the semantic aware vector embeddings. doing this alone
does not solve the recall problem, as the pool of documents is limited by the initial ranking, this
approach can only improve the ordering of the already gathered pool, and by extension, precision.

using broad strokes, ladr uses the first ranking to seed an exploration of semantically similar
documents in the additional re-ranking rounds

two strategies, adaptive and proactive

"This is similar to an idea proposed by [26] for the purposes of finding additional documents to
score when re-ranking; ours differs from this work because we are exploring similar documents as a
method of pruning the search space of dense retrieval while keeping comparable performance to an
exhaustive search."

HNSW 

Preparation

Index documents using a standard lexical retrieval model

For each document, calculate the K more similar neighbours, using TCT-ColBert-HNP for example expand
later.....

Proactive Algorithm

Obtain n documents using the query input into a BM25 model to use as the seed

Expand document pool by unioning the seed document with the K nearest neighbours of those documents

Final results of the expansion are stored in R1, this gives both the ranking and the expanded pool
The complexity and time constraints are bounded by n (seed set size) and k 

Time complexity of O(kn) Space complexity of O(Dn)


Adaptive Algorithm Obtain n documents using the query input into a BM25 model to use as the seed
Score seeds Expand document pool by unioning the seed document with the K nearest neighbours of
those documents Skip docs we have seen Final results of the expansion are stored in R1, this gives
both the ranking and the expanded pool The complexity and time constraints are bounded by n (seed
set size) and k 

Potential for spending less time on less promising documents, but can result in poor complexity if
the document choice is very poor

Time complexity of O(D) Space complexity of O(Dn)

Proactive is more predictable in runtime, engineering is easier as it can be easily extracted to a
separate service if necessary. As adaptive has an iterative approach it could require the separate
service to be called multiple times.

Main contribution

LADR is a new technique to reduction computational load in dense retrieval. It is competitive with
other approximate nearest neighbour techniques, its parameters allow for a system which is flexible
and able to be optimized for specific use cases. State of the art for low latency apporximate dense
retrieval.

Research Questions

How does LADR compare with other ANN techniques in dense retrieval w.r.t performance and
computational load?
What should be considered when choosing better proactive and adaptive LADR?
Does the nearest neighbour graph need to be constructed using an exhaustive search? Or can it be
optimized by using an approximation approach like HNSW?


