introduction 

Dense retrieval is gaining popularity, driven by the widespread adoption of pre-trained language
models such as BERT and T5, which excel at learning semantic representations of words. This approach
involves several trade-offs, particularly noticeable in re-ranking pipelines where choices must be
made about the size of the initial ranked set and the computational budget allocated for further
re-ranking. In the models discussed in the referenced papers, a parameter, K, represents the number
of nearest neighbors considered for both scoring and exploration purposes.

One of the key advantages of dense retrieval is its ability to improve recall by enabling queries
based on semantic meaning rather than exact lexical matches. However, this benefit comes at the cost
of increased computational demand during both indexing and query-time. Additionally, techniques that
use approximation approaches in the second re-ranking phase often suffer from diminished recall,
which is counterproductive to their primary objective.

Ideally, to surpass the performance of traditional models, an exhaustive search over all documents
would be performed. However, such a strategy scales linearly with the number of documents and allows
no pruning, in contrast to lexical approaches.

Enhancing recall remains a significant challenge in information retrieval. Alternative methods, such
as those employed by models like SPADE\ref{spade}, leverage query expansion to identify semantically similar
documents in the initial stage, potentially improving recall with reduced computational overhead at
query-time, though still requiring additional effort during indexing.

In dense retrieval, models are broadly classified into two categories based on their interaction
with queries: interactive and non-interactive. Non-interactive models employ static vector
embeddings which remain unchanged regardless of the query context. In contrast, interactive models
dynamically adjust the interaction between the query and document representations in the index,
enabling more responsive and context-sensitive retrieval.

A prevalent technique in this field is the use of the top-ranked results from an initial query as a
"seed" to guide the re-ranking and exploration processes. This approach leverages the initial
results to refine and enhance subsequent retrieval efforts.

Supporting these techniques is the clustering hypothesis, which posits that documents similar in
content are likely to be relevant to the same queries. This hypothesis is fundamental to many
advanced exploration techniques in dense retrieval, as it allows for more efficient and effective
identification of relevant documents through clustering-based strategies.


